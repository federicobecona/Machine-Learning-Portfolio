[
    {
        "unidad":"CRISP-DM",
        "titulo":"PD3",
        "descripcion":"En este ejercicio se aplican técnicas de pre procesamiento y obtención de estadísticas para el dataset wine utiliando funciones de Python.",
        "contenido":"h3>>Pasos==p>>- Se descargó el dataset de Wine.==p>>- Se imprimieron las columnas de las primeras 10 filas.==p>>- Se convirtieron los valores numéricos de string a float.==p>>- Se obtuvieron los valores mínimos y máximos para cada columna.==p>>- Se obtuvo la media y la desviación estándar de los valores de cada columna.==p>>- Se normalizaron y se estandarizaron los valores del dataset original.==p>>- Se dividió el dataset en conjuntos de entrenamiento y testing.==br==h3>>Código==code>>.from csv import reader==br==code>>.from math import sqrt==br==code>>.from random import randrange==br==code>>.import pandas as pd==br==code>>.==br==code>>.def load_csv(filename):==br==code>>.\u00a0    dataset = list()==br==code>>.\u00a0    with open(filename, 'r') as file:==br==code>>.\u00a0\u00a0        csv_reader = reader(file)==br==code>>.\u00a0\u00a0        for row in csv_reader:==br==code>>.\u00a0\u00a0\u00a0            if not row:==br==code>>.\u00a0\u00a0\u00a0\u00a0                continue==br==code>>.\u00a0\u00a0\u00a0            dataset.append(row)==br==code>>.\u00a0\u00a0        return dataset==br==code>>.==br==code>>.def str_column_to_float(dataset, column):==br==code>>.\u00a0    for row in dataset:==br==code>>.\u00a0\u00a0        row[column] = float(row[column].strip())==br==code>>.==br==code>>.def dataset_minmax(dataset):==br==code>>.\u00a0    minmax = list()==br==code>>.\u00a0    for i in range(len(dataset[0])):==br==code>>.\u00a0\u00a0        col_values = [row[i] for row in dataset]==br==code>>.\u00a0\u00a0        value_min = min(col_values)==br==code>>.\u00a0\u00a0        value_max = max(col_values)==br==code>>.\u00a0\u00a0        minmax.append([value_min, value_max])==br==code>>.\u00a0    return minmax==br==code>>.==br==code>>.def column_means(dataset):==br==code>>.\u00a0    means = [0 for i in range(len(dataset[0]))]==br==code>>.\u00a0    for i in range(len(dataset[0])):==br==code>>.\u00a0\u00a0        col_values = [row[i] for row in dataset]==br==code>>.\u00a0\u00a0        means[i] = sum(col_values) / float(len(dataset))==br==code>>.\u00a0    return means==br==code>>.==br==code>>.def column_stdevs(dataset, means):==br==code>>.\u00a0    stdevs = [0 for i in range(len(dataset[0]))]==br==code>>.\u00a0    for i in range(len(dataset[0])):==br==code>>.\u00a0\u00a0        variance = [pow(row[i]-means[i], 2) for row in dataset]==br==code>>.\u00a0\u00a0        stdevs[i] = sum(variance)==br==code>>.\u00a0\u00a0        stdevs = [sqrt(x/(float(len(dataset)-1))) for x in stdevs]==br==code>>.\u00a0    return stdevs==br==code>>.==br==code>>.def normalize_dataset(dataset, minmax):==br==code>>.\u00a0    for row in dataset:==br==code>>.\u00a0\u00a0        for i in range(len(row)):==br==code>>.\u00a0\u00a0\u00a0            row[i] = (row[i] - minmax[i][0])==br==code>>.\u00a0\u00a0\u00a0            (minmax[i][1] - minmax[i][0])==br==code>>.==br==code>>.def standardize_dataset(dataset, means, stdevs):==br==code>>.\u00a0    for row in dataset:==br==code>>.\u00a0\u00a0        for i in range(len(row)):==br==code>>.\u00a0\u00a0\u00a0            row[i] = (row[i] - means[i]) / stdevs[i]==br==code>>.==br==code>>.def train_test_split(dataset, split=0.60):==br==code>>.\u00a0    train = list()==br==code>>.\u00a0    train_size = split * len(dataset)==br==code>>.\u00a0    dataset_copy = list(dataset)==br==code>>.\u00a0    while len(train) < train_size:==br==code>>.\u00a0\u00a0        index = randrange(len(dataset_copy))==br==code>>.\u00a0\u00a0        train.append(dataset_copy.pop(index))==br==code>>.\u00a0    return train, dataset_copy==br==code>>.==br==code>>.==br==code>>.input_file = wine.csv==br==code>>.dataset = load_csv(input_file)==br==code>>.for i in range(10):==br==code>>.\u00a0    print(dataset[i])==br==code>>.for i in range(14):==br==code>>.\u00a0    str_column_to_float(dataset,i)==br==code>>.minmax = dataset_minmax(dataset)==br==code>>.means = column_means(dataset)==br==code>>.stdevs = column_stdevs(dataset, means)==br==code>>.print(minmax)==br==code>>.print(means)==br==code>>.print(stdevs)==br==code>>.normalized_dataset = dataset.copy()==br==code>>.normalize_dataset(normalized_dataset, minmax)==br==code>>.standarized_dataset = dataset.copy()==br==code>>.standardize_dataset(standarized_dataset, means, stdevs)==br==code>>.train_test_split(dataset)==br==br==h3>>Resultados obtenidos==img>>UT2-PD3.jpg>>1500>>300"
    },
    {
        "unidad":"Casos",
        "titulo":"Predicción de valores inmobiliarios",
        "descripcion":"Esta TA consiste en...",
        "contenido":"h1>>Visitar esta página ==p>> HELLO"
    },
    {
        "unidad":"Casos",
        "titulo":"Predicción de altura según restos óseos",
        "descripcion":"Esta TA consiste en...",
        "contenido":"h1>>Visitar esta página ==p>> chau "
    },
    {
        "unidad":"CRISP-DM",
        "titulo":"TA1",
        "descripcion":"Esta TA consiste en...",
        "contenido":"h1>>Visitar esta página ==p>> hola ==a>>hola>>https://google.com==hr==img>>prueba.jpg>>400>>400"
    },
    {
        "unidad":"Algoritmos lineales",
        "titulo":"PD2",
        "descripcion":"Esta PD consiste en...",
        "contenido":"h1>>Visitar esta página ==p>> hola"
    },
    {
        "unidad":"Algoritmos no lineales",
        "titulo":"TA2",
        "descripcion":"Esta TA consiste en...",
        "contenido":"h1>>Visitar esta página ==p>> hola"
    }
]