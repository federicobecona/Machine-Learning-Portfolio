[
    {
        "unidad":"CRISP-DM",
        "titulo":"PD3",
        "descripcion":"En este ejercicio se aplican técnicas de pre procesamiento y obtención de estadísticas para el dataset Wine utiliando funciones de Python.",
        "contenido":"h3>>Pasos==p>>- Se descargó el dataset Wine.==p>>- Se imprimieron las columnas de las primeras 10 filas.==p>>- Se convirtieron los valores numéricos de string a float.==p>>- Se obtuvieron los valores mínimos y máximos para cada columna.==p>>- Se obtuvo la media y la desviación estándar de los valores de cada columna.==p>>- Se normalizaron y se estandarizaron los valores del dataset original.==p>>- Se dividió el dataset en conjuntos de entrenamiento y testing.==br==h3>>Código==code>>.from csv import reader==br==code>>.from math import sqrt==br==code>>.from random import randrange==br==code>>.import pandas as pd==br==code>>.import copy==br==code>>.==br==code>>.columns = ['Alcohol','Malic acid','Ash','Alcalinity of ash','Magnesium','Total phenols','Flavanoids','Nonflavanoid phenols','Proanthocyanins','Color intensity','Hue','OD280/OD315 of diluted wines','Proline']==br==code>>.==br==code>>.def load_csv(filename):==br==code>>.\u00a0\u00a0\u00a0\u00a0    dataset = list()==br==code>>.\u00a0\u00a0\u00a0\u00a0    with open(filename, 'r') as file:==br==code>>.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0        csv_reader = reader(file)==br==code>>.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0        for row in csv_reader:==br==code>>.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0            if not row:==br==code>>.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0                continue==br==code>>.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0            dataset.append(row)==br==code>>.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0        return dataset==br==code>>.==br==code>>.def str_column_to_float(dataset, column):==br==code>>.\u00a0\u00a0\u00a0\u00a0    for row in dataset:==br==code>>.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0        row[column] = float(row[column].strip())==br==code>>.==br==code>>.def dataset_minmax(dataset):==br==code>>.\u00a0\u00a0\u00a0\u00a0    minmax = list()==br==code>>.\u00a0\u00a0\u00a0\u00a0    for i in range(len(dataset[0])):==br==code>>.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0        col_values = [row[i] for row in dataset]==br==code>>.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0        value_min = min(col_values)==br==code>>.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0        value_max = max(col_values)==br==code>>.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0        minmax.append([value_min, value_max])==br==code>>.\u00a0\u00a0\u00a0\u00a0    return minmax==br==code>>.==br==code>>.def column_means(dataset):==br==code>>.\u00a0\u00a0\u00a0\u00a0    means = [0 for i in range(len(dataset[0]))]==br==code>>.\u00a0\u00a0\u00a0\u00a0    for i in range(len(dataset[0])):==br==code>>.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0        col_values = [row[i] for row in dataset]==br==code>>.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0        means[i] = sum(col_values) / float(len(dataset))==br==code>>.\u00a0\u00a0\u00a0\u00a0    return means==br==code>>.==br==code>>.def column_stdevs(dataset, means):==br==code>>.\u00a0\u00a0\u00a0\u00a0    stdevs = [0 for i in range(len(dataset[0]))]==br==code>>.\u00a0\u00a0\u00a0\u00a0    for i in range(len(dataset[0])):==br==code>>.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0        variance = [pow(row[i]-means[i], 2) for row in dataset]==br==code>>.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0        stdevs[i] = sum(variance)==br==code>>.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0        stdevs = [sqrt(x/(float(len(dataset)-1))) for x in stdevs]==br==code>>.\u00a0\u00a0\u00a0\u00a0    return stdevs==br==code>>.==br==code>>.def normalize_dataset(dataset, minmax):==br==code>>.\u00a0\u00a0\u00a0\u00a0    for row in dataset:==br==code>>.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0        for i in range(len(row)):==br==code>>.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0            row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])==br==code>>.==br==code>>.==br==code>>.def standardize_dataset(dataset, means, stdevs):==br==code>>.\u00a0\u00a0\u00a0\u00a0    for row in dataset:==br==code>>.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0        for i in range(len(row)):==br==code>>.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0            row[i] = (row[i] - means[i]) / stdevs[i]==br==code>>.==br==code>>.def train_test_split(dataset, split=0.60):==br==code>>.\u00a0\u00a0\u00a0\u00a0    train = list()==br==code>>.\u00a0\u00a0\u00a0\u00a0    train_size = split * len(dataset)==br==code>>.\u00a0\u00a0\u00a0\u00a0    dataset_copy = list(dataset)==br==code>>.\u00a0\u00a0\u00a0\u00a0    while len(train) < train_size:==br==code>>.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0        index = randrange(len(dataset_copy))==br==code>>.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0        train.append(dataset_copy.pop(index))==br==code>>.\u00a0\u00a0\u00a0\u00a0    return train, dataset_copy==br==code>>.==br==code>>.input_file = \"wine.csv\"==br==code>>.dataset = load_csv(input_file)==br==code>>.print(\"\n- Primeras 10 filas:\")==br==code>>.for i in range(10):==br==code>>.\u00a0\u00a0\u00a0\u00a0    print(dataset[i])==br==code>>.strToFloatDataset = copy.deepcopy(dataset)==br==code>>.for i in range(len(columns)+1):==br==code>>.\u00a0\u00a0\u00a0\u00a0    str_column_to_float(strToFloatDataset,i)==br==code>>.print(\"\n- Primeras 10 filas dataset con floats:\")==br==code>>.for i in range(10):==br==code>>.\u00a0\u00a0\u00a0\u00a0    print(strToFloatDataset[i])==br==code>>.minmax = dataset_minmax(strToFloatDataset)==br==code>>.means = column_means(strToFloatDataset)==br==code>>.stdevs = column_stdevs(strToFloatDataset, means)==br==code>>.print(\"\n- Estadísticas: \")==br==code>>.for i in range(len(columns)):==br==code>>.\u00a0\u00a0\u00a0\u00a0    print(\"*\"+columns[i] + \": min \" + str(minmax[i][0]) + \",  max \" + str(minmax[i][1]) + \", media \" + str(means[i]) + \", desviación estándar \" + str(stdevs[i]))==br==code>>.normalized_dataset = copy.deepcopy(strToFloatDataset)==br==code>>.standarized_dataset = copy.deepcopy(strToFloatDataset)==br==code>>.train_test_split_dataset = copy.deepcopy(strToFloatDataset)==br==code>>.normalize_dataset(normalized_dataset, minmax)==br==code>>.standardize_dataset(standarized_dataset, means, stdevs)==br==code>>.train, test = train_test_split(train_test_split_dataset)==br==code>>.print(\"\n- Primeras 10 filas dataset estandarizado:\")==br==code>>.for i in range(10):==br==code>>.\u00a0\u00a0\u00a0\u00a0    print(standarized_dataset[i])==br==code>>.print(\"\n- Primeras 10 filas dataset normalizado:\")==br==code>>.for i in range(10):==br==code>>.\u00a0\u00a0\u00a0\u00a0    print(normalized_dataset[i])==br==code>>.print(\"\n- Primeras 10 filas de los dataset de train:\")==br==code>>.for i in range(10):==br==code>>.\u00a0\u00a0\u00a0\u00a0    print(train[i])==br==code>>.print(\"\n- Primeras 10 filas de los dataset de train:\")==br==code>>.\u00a0\u00a0\u00a0\u00a0for i in range(10):    ==br==code>>.\u00a0\u00a0\u00a0\u00a0    print(test[i])==br==br==h3>>Resultados==img>>UT2-PD3-1.jpg>>1200>>300==img>>UT2-PD3-2.jpg>>1200>>300==img>>UT2-PD3-3.jpg>>1200>>400==img>>UT2-PD3-4.jpg>>1200>>800==img>>UT2-PD3-5.jpg>>1200>>700"
    },
    {
        "unidad":"Casos",
        "titulo":"Predicción de valores inmobiliarios",
        "descripcion":"Esta TA consiste en...",
        "contenido":"h1>>Visitar esta página ==p>> HELLO"
    },
    {
        "unidad":"Casos",
        "titulo":"Predicción de altura según restos óseos",
        "descripcion":"Esta TA consiste en...",
        "contenido":"h1>>Visitar esta página ==p>> chau "
    },
    {
        "unidad":"CRISP-DM",
        "titulo":"TA1",
        "descripcion":"Esta TA consiste en...",
        "contenido":"h1>>Visitar esta página ==p>> hola ==a>>hola>>https://google.com==hr==img>>prueba.jpg>>400>>400"
    },
    {
        "unidad":"Algoritmos lineales",
        "titulo":"PD2",
        "descripcion":"Esta PD consiste en...",
        "contenido":"h1>>Visitar esta página ==p>> hola"
    },
    {
        "unidad":"Algoritmos no lineales",
        "titulo":"TA2",
        "descripcion":"Esta TA consiste en...",
        "contenido":"h1>>Visitar esta página ==p>> hola"
    }
]